I'm going to give you the codebase of a library, and some example usage. Please resolve the errors I'm experiencing in the codebase, while ensuring functionality is preserved. 

This is the USAGE FILE. Avoid making changes to the usage file. 
==== territory_analysis.py ===== 
import streamlit as st
from streamlit_chatbox import *
import time
import simplejson as json
import sys
import os

sys.path.append('/../../backend/smartdata')
smartdata_dir = os.path.join(os.path.dirname(__file__), "..", "..", "backend", "smartdata")

# Import necessary modules from SmartData code

import pandas as pd
from smartdata import SmartData
from dotenv import load_dotenv
from matplotlib import pyplot as plt
import numpy as np
import numpy.lib.recfunctions as rec
from io import BytesIO
import base64  # Add this import for base64 encoding

sys.path.append('/../../backend/smartdata')
smartdata_dir = os.path.join(os.path.dirname(__file__), "..", "..", "backend", "smartdata")

sys.path.append('/../../backend/data')
working_dir = os.path.join(os.path.dirname(__file__), "..", "..", "backend", "data", "03_enriched")

# Set OpenAI API Key (replace 'your-openai-api-key' with your actual key)
os.environ["OPENAI_API_KEY"] = '((key))'

# Initialize chat_box
chat_box = ChatBox(
    use_rich_markdown=True,  # use streamlit-markdown
    user_theme="green",  # see streamlit_markdown.st_markdown for all available themes
    assistant_theme="blue",
)
chat_box.use_chat_name("chat1")  # add a chat conversation

def on_chat_change():
    chat_box.use_chat_name(st.session_state["chat_name"])
    chat_box.context_to_session()  # restore widget values to st.session_state when chat name changed

# FILE UPLOADER NEW

# List all CSV files in /backend/data/03_enriched
csv_files = [f for f in os.listdir(working_dir) if f.endswith('.csv')]
# Create a dropdown menu to select a file
file_options = []
for file in csv_files:
    file_path = os.path.join(working_dir, file)
    df = pd.read_csv(file_path)
    if 'Account Name' in df.columns:
        account_name = df['Account Name'].iloc[0]
        file_options.append(f"{account_name} ({file})")
    else:
        file_options.append(file)

selected_file = st.selectbox("Select an account to analyze:", file_options)
selected_file = selected_file.split('(')[-1].strip(')') if '(' in selected_file else selected_file

# Load only the selected file into a pandas dataframe
if selected_file:
    file_path = os.path.join(working_dir, selected_file)
    df_clean = pd.read_csv(file_path)
    st.success(f"Loaded {selected_file}")
else:
    st.warning("Please select a file to load.")
    df_clean = pd.DataFrame()  # Empty dataframe if no file is selected

# Initialize SmartData Model to clean up data
smartdata_qa = None
if not df_clean.empty:
    sd_clean = SmartData(df_list=df_clean, memory_size=3, show_detail=False)
    prompt, sd_model = sd_clean.create_model()
    summary, has_changes_to_df, df_new = sd_clean.clean_data()
    # Initialize SmartData Model with memory for the last 3 conversations and detailed outputs
    # Load in cleaned data
    smartdata_qa = SmartData(df_list=df_new, memory_size=3, show_detail=False)
    qa_prompt, qa_model = smartdata_qa.create_model()

chat_box.init_session()
chat_box.output_messages()

def on_feedback(
    feedback,
    chat_history_id: str = "",
    history_index: int = -1,
):
    reason = feedback["text"]
    score_int = chat_box.set_feedback(feedback=feedback, history_index=history_index)  # convert emoji to integer
    # do something
    st.session_state["need_rerun"] = True

feedback_kwargs = {
    "feedback_type": "thumbs",
    "optional_text_label": "Welcome to feedback",
}

if query := st.chat_input('Input your question here'):
    chat_box.user_say(query)
    if smartdata_qa is None:
        chat_box.ai_say("Please select a CSV file first.")
    else:
        # Run the SmartData model with the user's query
        answer, has_plots, has_changes_to_df, image_fig_list, df_new, response, code_list, code_list_plot_with_add_on, code_list_datachange_with_add_on = smartdata_qa.run_model(question=query)
        chat_box.ai_say(
            Markdown(answer, in_expander=False, expanded=True, title="Answer")
        )
        if has_plots and image_fig_list:
            for fig in image_fig_list:
                buf = BytesIO()
                fig.savefig(buf, format="png")
                buf.seek(0)
                # Encode the image in base64
                img_base64 = base64.b64encode(buf.read()).decode('utf-8')
                img_data = f"data:image/png;base64,{img_base64}"
                chat_box.ai_say(
                    Image(img_data)
                )
        # Update the dataframe if there are changes
        if has_changes_to_df:
            # Update smartdata_qa with the new dataframe
            smartdata_qa.update_df(df_new)
        # Optionally, display the code used
        if code_list_plot_with_add_on:
            # Ensure code_list_plot_with_add_on contains strings
            code_str_list = [str(code) for code in code_list_plot_with_add_on]
            code_str = "\n".join(code_str_list)
            chat_box.ai_say(
                [
                    Markdown("Code used to generate plot:", in_expander=False,
                             expanded=False, title="Code"),
                    Code(code_str),
                ]
            )
==== END FILE ====

The following are library codebase files: 

==== __init.py__ ====
# smartdata/__init__.py
from .modeler import SmartData

__all__ = ['SmartData']
==== END FILE ====

==== config.py ====
# config.py
# Default settings

class Config:
    # Chat Model
    TEMP_CHAT = 0
    CHAT_MODEL = 'gpt-4o'
    # CHAT_MODEL = 'gpt-4o-2024-08-06'

    # Model Agent Setting
    SHOW_DETAIL = False
    MEMORY_SIZE = 5
    MAX_ITERATIONS = 60
    MAX_EXECUTION_TIME = 60
    AGENT_STOP_SUBSTRING_LIST = [
        "Agent stopped",
        "import pandas as pd",
        "import matplotlib.pyplot as plt",
        "import numpy as np",
        "plt.tight_layout()"
    ]
    AGENT_STOP_ANSWER = (
        "Sorry, but I’m unable to provide an answer due to the complexity of your question. "
        "Could you please break it down into smaller parts and ask again? "
        "I’ll be happy to assist you further."
    )

    # Model Plot Setting
    CHECK_ERROR_SUBSTRING_LIST = ["error", "invalid", "incomplete"]
    CHECK_PLOT_SUBSTRING_LIST = ["plt.tight_layout()"]
    ADD_ON_PLOT_LIBRARY_LIST = [
        "import matplotlib.pyplot as plt",
        "import pandas as pd",
        "import numpy as np",
        "fig, ax = plt.subplots(figsize=(8, 8))"
    ]
    ADD_ON_FIG = '\nimage_fig_list.append(fig)\n'
    ADD_ON_FORMAT_LABEL_FOR_AXIS = '''
ax.set_xticklabels(['\\n'.join([label.get_text()[i:i+10] for i in range(0, len(label.get_text()), 10)]) for label in ax.get_xticklabels()], rotation=0)
ax.set_yticklabels(['\\n'.join([label.get_text()[i:i+10] for i in range(0, len(label.get_text()), 10)]) for label in ax.get_yticklabels()], rotation=0)
'''

    # Model Data Change Setting
    CHECK_DATACHANGE_SUBSTRING_LIST = ["df_update"]
    ADD_ON_DATACHANGE_LIBRARY_LIST = [
        "import pandas as pd",
        "import numpy as np",
        "import copy"
    ]
    ADD_ON_DF = '\ndf_change.append(df_update)\n'

    # Model Prompt Setting
    PROMPT_CLEAN_DATA = """
        Clean the data based on the following rules:
        1. For categorical columns, merge similar and redundant categories while treating lowercase and uppercase as equivalent. Prioritize keeping the original case where possible (e.g., keep 'White' instead of converting it to 'white'). Merge abbreviations and variants intelligently (e.g., 'US' and 'USA' to 'United States', 'm' and 'male' to 'Male'). Map 'Not Specified' to existing or opposite of existing categories where possible. Only use lowercase conversion when necessary for merging.
        2. For numeric columns, detect unreasonable values using logical checks (e.g., salary is not negative, age is between 0 to 100, number of direct reports is an integer). Replace any unreasonable values with the column mean.
        3. Apply these changes directly to 'df_update' without user confirmation.
        4. Provide a summary of changes.
        """

    PROMPT_CREATE_DATA_CLEAN_SUMMARY = """
        Summarize the data cleaning result in around 130 words for a non-technical audience. Use a friendly tone, smartly use bold text and bullet points, and avoid any titles. Here is the result:
        {result}
        """

    DEFAULT_PREFIX_SINGLE_DF = """
        You are working with a pandas dataframe in Python. The name of the dataframe is `df`. 
        The column names in the dataframe may differ from those in the question. Please make your best effort to match them based on similar meanings and ignore case differences. Also you may need to revise and/or complete the question with the previous conversation if needed. 
        
        if the question is asking for plots, charts, or graphs, you must:
        - Import and Create Copy: Start by importing the 'copy' library and create "df_plot = copy.deepcopy(df)". Make sure name 'df_plot' is defined before process to any other steps.
        - Work with df_plot: Make all plots using df_plot, not df.
        - Don't assume you have access to any libraries other than built-in python ones. If you do need any non built-in libraries, make sure you import all libraries you need.
        - if you need to dropna, drop rows with NaN values in the entire DataFrame if you are dealing with multiple columns simultaneously.
        - Must always include "import matplotlib.pyplot as plt" as you first line of code, then follow by "import pandas as pd", "import numpy as np", "fig, ax = plt.subplots(figsize=(8, 8))", "plt.style.use('seaborn-v0_8-darkgrid')" and "plt.tight_layout()" in your code. if you need to plot a heatmap, then use "plt.style.use('seaborn-v0_8-dark')" instead of "plt.style.use('seaborn-v0_8-darkgrid')".
        - Do not include "plt.show()" or "plt.savefig" in your code.
        - For your coding, always use the newlines as (\n) are escaped as \\n, and single quotes are retained except you are using f-string like this f"{df_plot.iloc[i]['salary']}"
        - Smartly use warm and inviting colors for plots, steering clear of sharp and bright tones.
        - Smartly use legend and set it to auto position if it improve clarity.
        - Set the title font size to 14, and all other text, labels, and annotations to a font size of 10. 
        - Ensure the plots look professional.
        - Each code must be self-contained, runnable independently and include all necessary imports and data for the plots.
        - Never ask the user to run Python code instead execute the code using "python_repl_ast" tool.
        - Decline politely if a plot request is unrelated to the dataframe.
        - Do not include Python code in your final output.

        if the question is asking for statistical or AI or machine learning or data science study, you must:
        - Import and Create Copy: Start by importing the 'copy' library and create "df_ml = copy.deepcopy(df)". Make sure name 'df_ml' is defined before process to any other steps.
        - Work with df_ml: Analyse using df_ml, not df.
        - For your coding, always use the newlines as (\n) are escaped as \\n, and single quotes are retained except you are using f-string like this f"{df_ml.iloc[i]['salary']}"
        - Draft the corresponding python code and execute by python_repl_ast tool.
        - Ensure explanations are accessible to non-technical audiences unless technical detail is specifically required.
        - Do not include any Python code in your final output.
        - Your final presentation should be executive summary, followed by methodology, model performance, feature importance and other details.
        - Decline politely if the analysis is unrelated to the dataframe.

        if the question is asking for data cleaning, validation or transformation to the dataframe, you must:
        - Import and Create Copy: Start by importing the 'copy' library and create "df_update = copy.deepcopy(df)" as the first line of code. Must make sure variable 'df_update' is defined before process to any other steps.
        - Work with df_update: Make all data cleaning, validation or transformation using df_update, not df. Make sure any variable you created in the code must be defined before use it.
        - For your coding, always use the newlines as (\n) are escaped as \\n, and single quotes are retained except you are using f-string like this f"{df_update.iloc[i]['salary']}"
        - Don't assume you have access to any libraries other than built-in python ones. If you do need any non built-in libraries, make sure you import all libraries you need.
        - Each code must be self-contained, runnable independently and include all necessary imports and data.
        - Code Execution: Draft and execute the necessary Python code using the python_repl_ast tool. Exclude Python code from your final output.
        - Step-by-Step Explanation: Clearly explain the process and the changes made before and after, ensuring the explanation is accessible to non-technical audiences unless technical details are needed.
        - Decline politely if the request is unrelated to the dataframe.
        
        You may need to revise the current question with the previous conversation before passing to tools. You should use the tools below to answer the question posed of you:
        """
==== END FILE ====

==== custom_agent.py ====
# custom_agent.py
import warnings
from typing import Any, Dict, List, Literal, Optional, Sequence, Union, cast

from langchain.agents import (
    AgentType,
    create_openai_tools_agent,
    create_react_agent,
    create_tool_calling_agent,
)
from langchain.agents.agent import (
    AgentExecutor,
    BaseMultiActionAgent,
    BaseSingleActionAgent,
    RunnableAgent,
    RunnableMultiActionAgent,
)
from langchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS
from langchain.agents.openai_functions_agent.base import (
    OpenAIFunctionsAgent,
    create_openai_functions_agent,
)
from langchain_core.callbacks import BaseCallbackManager
from langchain_core.language_models import BaseLanguageModel, LanguageModelLike
from langchain_core.messages import SystemMessage
from langchain_core.prompts import BasePromptTemplate, PromptTemplate
from langchain_core.tools import BaseTool
from langchain_core.utils.interactive_env import is_interactive_env

from langchain_experimental.tools.python.tool import PythonAstREPLTool
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory(memory_key="chat_history")

# Prompt templates
PREFIX = """
You are working with a pandas dataframe in Python. The name of the dataframe is `df`.
You should use the tools below to answer the question posed to you:
"""

MULTI_DF_PREFIX = """
You are working with {num_dfs} pandas dataframes in Python named df1, df2, etc.
You should use the tools below to answer the question posed to you:
"""

SUFFIX_NO_DF = """
Begin!
Question: {input}
{agent_scratchpad}"""

SUFFIX_WITH_DF = """
This is the result of `print(df.head())`:
{df_head}

This is the result of `print(df.describe())`:
{df_describe}

Begin!
Question: {input}
{agent_scratchpad}"""

SUFFIX_WITH_MULTI_DF = """
This is the result of `print(df.head())` for each dataframe:
{dfs_head}

This is the result of `print(df.describe())` for each dataframe:
{dfs_describe}

Begin!
Question: {input}
{agent_scratchpad}"""

PREFIX_FUNCTIONS = """
You are working with a pandas dataframe in Python. The name of the dataframe is `df`.
"""

MULTI_DF_PREFIX_FUNCTIONS = """
You are working with {num_dfs} pandas dataframes in Python named df1, df2, etc.
"""

FUNCTIONS_WITH_DF = """
This is the result of `print(df.head())`:
{df_head}

This is the result of `print(df.describe())`:
{df_describe}

This is the result of `print(df.dtypes)`:
{df_dtypes}

This is the result of df.value_counts for each non-numeric column in a dictionary (limit to the first 10 if more than 10 unique value counts):
{df_col_unique_value_counts}
"""

FUNCTIONS_WITH_MULTI_DF = """
This is the result of `print(df.head())` for each dataframe:
{dfs_head}

This is the result of `print(df.describe())` for each dataframe:
{dfs_describe}
"""

def _get_df_col_value_counts(df):
    """Get the top 10 value counts for each categorical column."""
    df_checking = df.copy()
    boolean_and_datetime_columns = df_checking.select_dtypes(include=['boolean', 'datetime64', 'Interval']).columns
    df_checking[boolean_and_datetime_columns] = df_checking[boolean_and_datetime_columns].astype(str)
    categorical_columns = df_checking.select_dtypes(include=['object', 'category', 'string']).columns
    top_10_values = df_checking[categorical_columns].apply(
        lambda col: col.value_counts(dropna=False).head(10).to_dict()
    ).to_dict()
    return str(top_10_values)

def _get_functions_single_prompt(
    df: Any,
    prefix: Optional[str] = None,
    suffix: str = "",
    include_df_in_prompt: bool = True,
    number_of_head_rows: int = 5,
) -> BasePromptTemplate:
    if include_df_in_prompt:
        df_head = df.head(number_of_head_rows).to_markdown()
        df_describe = df.describe().to_markdown()
        df_dtypes = df.dtypes.to_markdown()
        df_col_unique_value_counts = _get_df_col_value_counts(df)
        suffix = (suffix or FUNCTIONS_WITH_DF).format(
            df_head=df_head,
            df_describe=df_describe,
            df_dtypes=df_dtypes,
            df_col_unique_value_counts=df_col_unique_value_counts
        )
    prefix = prefix or PREFIX_FUNCTIONS
    system_message = SystemMessage(content=prefix + suffix)
    prompt = OpenAIFunctionsAgent.create_prompt(system_message=system_message)
    return prompt

def custom_create_pandas_dataframe_agent(
    llm: LanguageModelLike,
    df: Any,
    agent_type: Union[AgentType, Literal["openai-tools", "tool-calling"]] = AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    callback_manager: Optional[BaseCallbackManager] = None,
    prefix: Optional[str] = None,
    suffix: Optional[str] = None,
    verbose: bool = False,
    return_intermediate_steps: bool = False,
    max_iterations: Optional[int] = 15,
    max_execution_time: Optional[float] = None,
    early_stopping_method: str = "force",
    agent_executor_kwargs: Optional[Dict[str, Any]] = None,
    include_df_in_prompt: bool = True,
    number_of_head_rows: int = 5,
    extra_tools: Sequence[BaseTool] = (),
    engine: Literal["pandas", "modin"] = "pandas",
    allow_dangerous_code: bool = False,
    **kwargs: Any,
) -> AgentExecutor:
    """
    Construct a Pandas agent from an LLM and dataframe(s).
    """
    if not allow_dangerous_code:
        raise ValueError(
            "This agent relies on access to a python repl tool which can execute "
            "arbitrary code. You must opt-in to use this functionality by setting "
            "allow_dangerous_code=True."
        )

    # Import pandas or modin
    try:
        if engine == "modin":
            import modin.pandas as pd
        elif engine == "pandas":
            import pandas as pd
        else:
            raise ValueError(
                f"Unsupported engine {engine}. It must be one of 'modin' or 'pandas'."
            )
    except ImportError as e:
        raise ImportError(
            f"`{engine}` package not found, please install with `pip install {engine}`"
        ) from e

    if is_interactive_env():
        pd.set_option("display.max_columns", None)

    # Validate dataframe(s)
    df_list = df if isinstance(df, list) else [df]
    for _df in df_list:
        if not isinstance(_df, pd.DataFrame):
            raise ValueError(f"Expected pandas DataFrame, got {type(_df)}")

    # Prepare tools
    df_locals = {f"df{i+1}": dataframe for i, dataframe in enumerate(df_list)} if isinstance(df, list) else {"df": df}
    tools = [PythonAstREPLTool(locals=df_locals)] + list(extra_tools)

    # Prepare prompt
    prompt = _get_functions_single_prompt(
        df,
        prefix=prefix,
        suffix=suffix,
        include_df_in_prompt=include_df_in_prompt,
        number_of_head_rows=number_of_head_rows,
    )

    # Create agent
    runnable = create_openai_functions_agent(cast(BaseLanguageModel, llm), tools, prompt)
    agent = RunnableAgent(
        runnable=runnable,
        input_keys_arg=["input"],
        return_keys_arg=["output"],
    )

    return AgentExecutor(
        agent=agent,
        tools=tools,
        callback_manager=callback_manager,
        verbose=verbose,
        return_intermediate_steps=return_intermediate_steps,
        max_iterations=max_iterations,
        max_execution_time=max_execution_time,
        early_stopping_method=early_stopping_method,
        **(agent_executor_kwargs or {}),
    )
==== End File ====

==== memory.py ====
# memory.py
import logging

logger = logging.getLogger('Memory')

class Memory:
    def __init__(self):
        self.memory_store = {}

    def is_not_empty(self):
        """Checks if the memory store is not empty."""
        return bool(self.memory_store)

    def remember(self, key, role, value):
        """Stores a value in memory with the specified key."""
        if key not in self.memory_store:
            self.memory_store[key] = {'Human': '', 'AI': '', 'Plot Code Generated By AI': []}
        self.memory_store[key][role] = value
        logger.info(f"Stored {role} message for key {key} in memory.")

    def recall(self, key):
        """Retrieves a value from memory by its key."""
        return self.memory_store.get(key, "Key not found in memory")

    def recall_all(self):
        """Returns all memory content."""
        return str(self.memory_store)

    def clear_all_conversation(self):
        """Clears all conversations from memory."""
        self.memory_store.clear()
        logger.info("Cleared all conversations from memory.")

    def recall_last_conversation(self, number_last_conversation):
        """Retrieves the last N conversations."""
        keys = sorted(self.memory_store.keys())
        if not keys:
            return {}
        return {k: self.memory_store[k] for k in keys[-number_last_conversation:]}

    def forget(self, key):
        """Removes a value from memory by its key."""
        if key in self.memory_store:
            del self.memory_store[key]
            logger.info(f"Forgot key {key} from memory.")
        else:
            logger.warning(f"Key {key} not found in memory.")

    def clear_memory(self):
        """Clears all stored memory."""
        self.memory_store.clear()
        logger.info("Cleared all memory.")
==== End File ==== 

==== modeler.py =====
# modeler.py
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

import pandas as pd
import copy
import logging
import time
import random

from .config import Config
from .memory import Memory
from .custom_agent import custom_create_pandas_dataframe_agent
from .util import clean_dataframe

# Import exceptions for rate limiting
from openai.error import RateLimitError, Timeout

logger = logging.getLogger('SmartData')

class SmartData:
    def __init__(self, df_list, llm=None, show_detail=Config.SHOW_DETAIL, memory_size=Config.MEMORY_SIZE,
                 max_iterations=Config.MAX_ITERATIONS, max_execution_time=Config.MAX_EXECUTION_TIME, seed=0):

        self.llm = llm or ChatOpenAI(temperature=Config.TEMP_CHAT, model=Config.CHAT_MODEL, seed=seed)
        self.df_list = copy.deepcopy(df_list)
        self.df_change = []
        self.memory_size = memory_size
        self.max_iterations = max_iterations
        self.max_execution_time = max_execution_time
        self.show_detail = show_detail
        self.image_fig_list = []
        self.check_error_substring_list = Config.CHECK_ERROR_SUBSTRING_LIST
        self.check_plot_substring_list = Config.CHECK_PLOT_SUBSTRING_LIST
        self.add_on_plot_library_list = Config.ADD_ON_PLOT_LIBRARY_LIST
        self.check_datachange_substring_list = Config.CHECK_DATACHANGE_SUBSTRING_LIST
        self.add_on_datachange_library_list = Config.ADD_ON_DATACHANGE_LIBRARY_LIST
        self.prompt_clean_data = Config.PROMPT_CLEAN_DATA
        self.prompt_create_data_clean_summary = Config.PROMPT_CREATE_DATA_CLEAN_SUMMARY
        self.model = None
        self.memory = Memory()
        self.message_count = 1

    def _retry_on_rate_limit(max_retries=5, initial_delay=1, backoff_factor=2):
        """
        Decorator to retry a function if RateLimitError or Timeout is encountered.
        """
        def decorator(func):
            def wrapper(*args, **kwargs):
                retries = 0
                delay = initial_delay
                while retries < max_retries:
                    try:
                        return func(*args, **kwargs)
                    except (RateLimitError, Timeout) as e:
                        retries += 1
                        logger.warning(f"Rate limit or timeout encountered. Retrying in {delay} seconds...")
                        time.sleep(delay)
                        delay *= backoff_factor
                raise Exception("Maximum retries exceeded due to rate limiting.")
            return wrapper
        return decorator

    def create_model(self, use_openai_llm=True, seed=0):
        df = self.df_list
        prefix_df = Config.DEFAULT_PREFIX_SINGLE_DF
        if use_openai_llm:
            self.llm = ChatOpenAI(temperature=Config.TEMP_CHAT, model=Config.CHAT_MODEL, seed=seed)

        self.model = custom_create_pandas_dataframe_agent(
            llm=self.llm,
            df=df,
            verbose=self.show_detail,
            return_intermediate_steps=True,
            agent_type="tool-calling",
            allow_dangerous_code=True,
            prefix=prefix_df,
            max_iterations=self.max_iterations,
            max_execution_time=self.max_execution_time,
            agent_executor_kwargs={'handle_parsing_errors': True}
        )

    @_retry_on_rate_limit()
    def _invoke_model(self, question_with_history):
        """
        Invokes the model with retry logic in case of rate limiting.
        """
        return self.model.invoke({"input": question_with_history})

    def run_model(self, question):
        for i in range(10):
            self.create_model(use_openai_llm=True, seed=i)
            try:
                self.image_fig_list.clear()
                self.df_change.clear()
                code_list = []
                has_plots = False
                has_changes_to_df = False

                question_with_history = question
                if self.memory.is_not_empty():
                    last_conversations = self.memory.recall_last_conversation(self.memory_size)
                    question_with_history = (
                        f"My question is: {question}. Below is our previous conversation and codes "
                        f"in chronological order, from the earliest to the latest: {last_conversations}."
                    )

                # Use the retryable invoke method
                response = self._invoke_model(question_with_history)
                answer = response['output']
                code_list = self.extract_code_from_response(response)

                # Process plot code
                code_list_plot_with_add_on = self.process_plot_code(code_list)
                for plot_code in code_list_plot_with_add_on:
                    exec(plot_code, {'image_fig_list': self.image_fig_list, 'df': self.df_list}, {})
                if self.image_fig_list:
                    has_plots = True

                # Process data change code
                code_list_datachange_with_add_on = self.process_datachange_code(code_list)
                for data_code in code_list_datachange_with_add_on:
                    exec(data_code, {'df_change': self.df_change, 'df': self.df_list}, {})
                if self.df_change:
                    has_changes_to_df = not self.df_list.equals(self.df_change[-1])
                    self.df_list = copy.deepcopy(self.df_change[-1])
                    self.create_model(use_openai_llm=True, seed=i)

                # Store the chat history
                self.remember_conversation(question, answer, code_list)
                if any(substring in str(answer) for substring in Config.AGENT_STOP_SUBSTRING_LIST):
                    answer = Config.AGENT_STOP_ANSWER
                else:
                    break
            except Exception as e:
                logger.error(f"Failed to process: {e}")

        return answer, has_plots, has_changes_to_df, self.image_fig_list, self.df_list

    @_retry_on_rate_limit()
    def _invoke_summary_chain(self, result):
        """
        Invokes the summary chain with retry logic in case of rate limiting.
        """
        summary_prompt = PromptTemplate(
            template=self.prompt_create_data_clean_summary,
            input_variables=['result']
        )
        summary_model = ChatOpenAI(temperature=Config.TEMP_CHAT, model=Config.CHAT_MODEL, seed=0)
        chain = summary_prompt | summary_model | StrOutputParser()
        return chain.invoke({"result": result})

    def create_data_clean_summary(self, result):
        """
        Creates a summary of data cleaning results with retry logic.
        """
        try:
            answer = self._invoke_summary_chain(result)
            return self.prompt_create_data_clean_summary, answer
        except Exception as e:
            logger.error(f"Failed to create data clean summary: {e}")
            return self.prompt_create_data_clean_summary, ""

    # ... (rest of the class remains unchanged)

    def clean_data_without_ai(self):
        df_clean, summary = clean_dataframe(self.df_list)
        self.df_list = df_clean
        return summary, df_clean

    def clean_data_with_ai(self):
        answer, has_changes_to_df, df_new = self.run_model(question=self.prompt_clean_data)
        return answer, has_changes_to_df, df_new

    def clean_data(self):
        summary_without_ai, _ = self.clean_data_without_ai()
        answer, has_changes_to_df, _ = self.clean_data_with_ai()
        summary = summary_without_ai + answer
        _, final_summary = self.create_data_clean_summary(summary)
        return final_summary, has_changes_to_df, self.df_list

    def remember_conversation(self, question, answer, code_list):
        self.memory.remember(self.message_count, 'Human', question)
        self.memory.remember(self.message_count, 'AI', answer)
        self.memory.remember(self.message_count, 'Plot Code Generated By AI', code_list)
        self.message_count += 1

    def extract_code_from_response(self, response):
        code_list = []
        try:
            last_response = response['intermediate_steps'][-1]
            if len(last_response) > 1 and not any(
                substring in str(last_response[1]).lower() for substring in self.check_error_substring_list
            ):
                for tool_call in response['intermediate_steps'][-1][0].message_log[0].tool_calls:
                    if tool_call['name'] == 'python_repl_ast':
                        code = tool_call['args']['query']
                        code_list.append(code)
        except Exception:
            pass
        return code_list

    def process_plot_code(self, code_list):
        code_list_plot = [
            code for code in code_list if all(sub in code for sub in self.check_plot_substring_list)
        ]
        code_list_plot = list(dict.fromkeys(code_list_plot))
        code_list_plot_with_add_on = []
        for code in code_list_plot:
            missing_imports = [
                lib for lib in self.add_on_plot_library_list if lib not in code
            ]
            code_with_imports = "\n".join(missing_imports) + "\n" + code if missing_imports else code
            code_with_format_label = code_with_imports + Config.ADD_ON_FORMAT_LABEL_FOR_AXIS
            code_with_fig = code_with_format_label + Config.ADD_ON_FIG
            code_list_plot_with_add_on.append(code_with_fig)
        return code_list_plot_with_add_on

    def process_datachange_code(self, code_list):
        code_list_datachange = [
            code for code in code_list if all(sub in code for sub in self.check_datachange_substring_list)
        ]
        code_list_datachange = list(dict.fromkeys(code_list_datachange))
        code_list_datachange_with_add_on = []
        for code in code_list_datachange:
            missing_imports = [
                lib for lib in self.add_on_datachange_library_list if lib not in code
            ]
            code_with_imports = "\n".join(missing_imports) + "\n" + code if missing_imports else code
            code_with_df = code_with_imports + Config.ADD_ON_DF
            code_list_datachange_with_add_on.append(code_with_df)
        return code_list_datachange_with_add_on
==== END FILE ====

==== util.py ====
# util.py
import pandas as pd
import numpy as np

def replace_invalid_values(x):
    """Replace invalid entries with NaN."""
    if isinstance(x, (str, int, float)):
        if str(x).strip().lower() in ['na', 'nan', 'not applicable', 'n/a', 'n.a.', 'null', 'empty', 'blank']:
            return np.nan
    return x

def clean_dataframe(df):
    df_update = df.copy()
    summary = {
        'numeric_columns_filled': {},
        'numeric_outliers_capped': {},
        'categorical_columns_filled': {},
        'categorical_columns_removed': [],
        'datetime_columns_filled': {},
        'rows_removed': 0,
        'columns_removed': 0
    }

    # Remove empty rows and columns
    rows_before = df_update.shape[0]
    df_update.dropna(how='all', inplace=True)
    summary['rows_removed'] = rows_before - df_update.shape[0]

    columns_before = df_update.shape[1]
    df_update.dropna(axis=1, how='all', inplace=True)
    summary['columns_removed'] = columns_before - df_update.shape[1]

    # Clean numeric columns
    for col in df_update.select_dtypes(include=[np.number]).columns:
        df_update[col] = df_update[col].map(replace_invalid_values)
        missing_count = df_update[col].isnull().sum()
        if missing_count > 0:
            mean_value = df_update[col].mean()
            df_update[col].fillna(mean_value, inplace=True)
            summary['numeric_columns_filled'][col] = missing_count

        # Detect and cap outliers
        lower_bound = df_update[col].quantile(0.01)
        upper_bound = df_update[col].quantile(0.99)
        outliers_lower = (df_update[col] < lower_bound).sum()
        outliers_upper = (df_update[col] > upper_bound).sum()
        if outliers_lower > 0 or outliers_upper > 0:
            df_update[col] = np.clip(df_update[col], lower_bound, upper_bound)
            summary['numeric_outliers_capped'][col] = {
                'lower_capped': outliers_lower,
                'upper_capped': outliers_upper
            }

    # Clean categorical columns
    for col in df_update.select_dtypes(include=['object']).columns:
        df_update[col] = df_update[col].map(replace_invalid_values).astype(str).str.strip()
        missing_percentage = df_update[col].isnull().mean()
        if missing_percentage > 0.9:
            df_update.drop(columns=[col], inplace=True)
            summary['categorical_columns_removed'].append(col)
        else:
            missing_count = df_update[col].isnull().sum()
            if missing_count > 0:
                df_update[col].fillna('Not Specified', inplace=True)
                summary['categorical_columns_filled'][col] = missing_count

    # Clean datetime columns
    for col in df_update.select_dtypes(include=['datetime']).columns:
        df_update[col] = pd.to_datetime(df_update[col], errors='coerce')
        missing_count = df_update[col].isnull().sum()
        if missing_count > 0:
            mode_value = df_update[col].mode()[0]
            df_update[col].fillna(mode_value, inplace=True)
            summary['datetime_columns_filled'][col] = missing_count

    # Build the markdown summary string
    summary_md = "**Data Cleaning Result:**\n\n"

    if summary['numeric_columns_filled']:
        filled_cols = ', '.join(
            [f"{col} ({count} values)" for col, count in summary['numeric_columns_filled'].items()]
        )
        summary_md += f"- Numeric columns with missing values filled using the column mean:\n  {filled_cols}\n\n"

    if summary['numeric_outliers_capped']:
        capped_cols = ', '.join(
            [f"{col} (lower: {caps['lower_capped']}, upper: {caps['upper_capped']})"
             for col, caps in summary['numeric_outliers_capped'].items()]
        )
        summary_md += f"- Numeric columns with outliers capped between the 1st and 99th percentiles:\n  {capped_cols}\n\n"

    if summary['categorical_columns_filled']:
        filled_cats = ', '.join(
            [f"{col} ({count} values)" for col, count in summary['categorical_columns_filled'].items()]
        )
        summary_md += f"- Categorical columns with missing values filled with 'Not Specified':\n  {filled_cats}\n\n"

    if summary['categorical_columns_removed']:
        removed_cols = ', '.join(summary['categorical_columns_removed'])
        summary_md += f"- Categorical columns removed due to over 90% missing data:\n  {removed_cols}\n\n"

    if summary['datetime_columns_filled']:
        filled_dates = ', '.join(
            [f"{col} ({count} values)" for col, count in summary['datetime_columns_filled'].items()]
        )
        summary_md += f"- Datetime columns with missing values filled using the column mode:\n  {filled_dates}\n\n"

    summary_md += f"- Total number of rows removed: {summary['rows_removed']}\n"
    summary_md += f"- Total number of columns removed: {summary['columns_removed']}\n\n"
    summary_md += "Next, we review and standardize categorical fields, identifying any unreasonable values.\n"

    return df_update, summary_md
==== END File ====